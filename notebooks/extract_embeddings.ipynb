{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uvfr9u3tYyY-"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U accelerate"
      ],
      "metadata": {
        "id": "Qu1F9hU3Y77Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm9kvyUPY_sv",
        "outputId": "cfe389d3-4dcd-44a9-8416-cb8536566dcc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize the training examples"
      ],
      "metadata": {
        "id": "thtyeCvEhkh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, Trainer, DataCollatorWithPadding, AutoTokenizer\n",
        "from datasets import Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train_path = \"drive/MyDrive/subtaskA_train_monolingual.jsonl\"\n",
        "model_name = \"bert-base-uncased\"\n",
        "\n",
        "def preprocess_function(examples, **fn_kwargs):\n",
        "    return fn_kwargs['tokenizer'](examples[\"text\"], truncation=True,padding=True)\n",
        "\n",
        "# load tokenizer from saved model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "train = pd.read_json(train_path,lines=True)\n",
        "train_dataset = Dataset.from_pandas(train)\n",
        "\n",
        "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True,  fn_kwargs={'tokenizer': tokenizer})\n"
      ],
      "metadata": {
        "id": "0rTdbkxJZCTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the tokens in drive.\n",
        "\n",
        "We extract only the relevent columns for model prediction. It is saved in drive for easy reuse using pickle.\n"
      ],
      "metadata": {
        "id": "NN3alIh7hrqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# code to save the tokens in a file\n",
        "only_tokens = tokenized_train_dataset.remove_columns(['text','source','model','token_type_ids','label'])\n",
        "with open(\"drive/MyDrive/tokenized_bert_truncated.pkl\",'wb') as f:\n",
        "  pickle.dump(only_tokens,f)\n",
        "# code to extract the tokens from the file\n",
        "with open(\"drive/MyDrive/tokenized_bert_truncated.pkl\",'rb') as f:\n",
        "  only_tokens = pickle.load(f)"
      ],
      "metadata": {
        "id": "vkQA9GGEZJx7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate training sequence embeddings\n",
        "\n",
        "We run the model on the training dataset batches and extract the [CLS] embeddings generated.\n",
        "The embeddings are stored in a list which is saved in a file using pickle."
      ],
      "metadata": {
        "id": "C0OWpWh6iJsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "model_name = \"bert-base-uncased\"\n",
        "model = BertModel.from_pretrained(model_name).to(device)\n",
        "batch_size = 8 #int(len(tokenized_train_dataset)/4)\n",
        "# print(len(only_tokens))\n",
        "batches = []\n",
        "predictions = []\n",
        "\n",
        "\n",
        "for i in tqdm(range(0, len(only_tokens),batch_size)):\n",
        "    inp_ids = torch.tensor(only_tokens[i:i+batch_size][\"input_ids\"], dtype=torch.int64, device=device)\n",
        "    att_masks = torch.as_tensor(only_tokens[i: i+batch_size][\"attention_mask\"], device=device)\n",
        "    preds = model(inp_ids, attention_mask = att_masks, output_hidden_states=True)\n",
        "    embeddings = torch.Tensor.tolist(preds.last_hidden_state[:,0,:].cpu())\n",
        "    predictions.append(embeddings)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwl7QI0QanOX",
        "outputId": "2fd11782-a653-4b2c-aa5e-9c322f125760"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14970/14970 [1:10:11<00:00,  3.55it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some processing of the generated list to flatten the batche. Also, saving the list for reuse later."
      ],
      "metadata": {
        "id": "327ReOjbimtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "\n",
        "final_embeds = list(chain.from_iterable(predictions))"
      ],
      "metadata": {
        "id": "KW6d0YqFgQBi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"drive/MyDrive/embeddings512.pkl\",'wb') as f:\n",
        "  pickle.dump(final_embeds,f)"
      ],
      "metadata": {
        "id": "M2HDezcsgsPi"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}